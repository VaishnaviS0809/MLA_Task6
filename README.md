# Task 6: K-Nearest Neighbors (KNN) Classification

## Objective
To build a KNN classification model using the Iris dataset and understand how the value of K affects accuracy.

## Dataset
Used the Iris dataset from Scikit-learn.

## Key Steps:
- Loaded and normalized the dataset.
- Split into training and testing sets.
- Trained KNN classifier with K from 1 to 10.
- Plotted K vs. Accuracy graph.
- Selected best K and evaluated using accuracy, confusion matrix, and classification report.
- Visualized decision boundaries (using 2 features).

## Results:
- **Best Accuracy:** ~100% with K = 6 (may vary slightly)
- **Tools Used:** Python, Scikit-learn, Matplotlib, NumPy

## What I Learned:
- How KNN works based on Euclidean distance.
- Importance of feature normalization.
- How to choose K value.
- Visualization of KNN decision boundaries.
